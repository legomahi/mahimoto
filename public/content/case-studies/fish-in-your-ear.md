---
title: "A Fish in Your Ear"
company: "Google"
sidebar_role: "Senior Staff Designer & Manager"
timeline_text: "2015 â€” 2019"
team_members:
  - "Pendar Yousefi (Lead & Manager)"
  - "Lindsey Boran (UXR)"
  - "Liu Liu (IXD)"
  - "Roque Silva (IxD)"
lead: "For as long as language has existed, humans have been fascinated by the idea of magical translation devices. At Google Translate, I had the opportunity to work on a product that makes that magic real. These are some of the projects I worked on in my early days, mostly as an individual contributor."

---

## DISCOVERING THE MAGIC

Beyond text translation, Google Translate apps have long offered translation for other modalities: instant camera translations, and real-time voice interpretation. At their best, these capabilities feel like magic and solve real user problems. They help language learners, tourists, students, and immigrants make sense of the world around them.

<!-- type: image-natural-size -->
![Final design 1](/images/fish-in-your-ear/shiri.gif)

## THE PROBLEM

Unfortunately, many of our users did not know these features existed. In some of the first user interviews I conducted after joining the team, I  observed participants often asked for features we already had. I confirmed the problem by running a quantitative survey that showed 40% of our users didn't know we had multimodal translation capabilities. 

<!-- type: image-full-width -->
![Small icons interface mockup](/images/fish-in-your-ear/hypothesis.webp)

## FIRST ATTEMPTS

My initial hypothesis was that the entry points into these tools were too small and obscure to be discovered. My first instinct was to make them bigger and more noticeable. So I experimented with new UIs that did just that. **To my surprise, in our controlled experiments this had the opposite effect! Usage of camera and conversation actually went down**. So what was going on? When I dug in, I found that many people simply ignored colorful things below the main box, often assuming they were unimportant ads or promotions. I even got complaints from an engineering executive who happened to be in our small experiment slice with the new UI and he couldn't find the conversation feature, despite being very familiar with our old UI.

<!-- type: image-full-width -->
![Small icons interface mockup](/images/fish-in-your-ear/first-designs.webp)

<!-- type: image-full-width -->
![Small icons interface mockup](/images/fish-in-your-ear/what-users-saw.webp)

## BACK TO THE DRAWING BOARD

So I went back to the drawing board. This time, my approach was to introduce minimum changes I could make to the existing UI that people were familiar with to make those features more clearly visible. I tweaked the icons, added text labels, and split the voice feature into its two separate use cases which I had found in user research: dictation and conversation. **This worked! Usage of multimodal features increased across the board, with the handwriting being used as much as 25% more than it was before**! We even started seeing tweets from people who thought these were new features, even though they existed for years.

<!-- type: image-grid -->
![Larger icons interface mockup](/images/fish-in-your-ear/take2.webp)
![Updated interface with larger icons](/images/fish-in-your-ear/twitter.webp)


## Improving the conversation UI

Improving feature discovery was only the beginning. I also wanted to make sure we deliver on the promise of magic through our multimodal capabilities. Starting with the conversation mode, I wanted to make it easier and more intuitive to use.

Our old conversation mode UI had 3 buttons: two buttons in the left and right for each language, and a big mic icon in the middle (i.e. "Magic Mic"). The Magic Mic was supposed to know when people were talking, what language they were speaking in, when they stopped talking, and when to translate, all without any additional input from users. It was magical when it worked!

<!-- type: image-full-width -->
![Conversation interface design](/images/fish-in-your-ear/conversation.webp)

## WHEN YOU TRY TO DO TOO MUCH

The problem was, for some languages the Magic Mic wasn't quite as accurate as it was for others. And because the UI emphasized the Magic Mic, many people were only using that, not even realizing there are two other manual language buttons.
As a result, they were encountering errors and abandoning this mode for other options like typing.

<!-- type: image-natural-size -->
![Final design 1](/images/fish-in-your-ear/convo.gif)

## A MORE BALANCED APPROACH

Following I lessons I learned from improving the discoverability by making simple changes, I asked myself: what is the simplest change we can make to the UI to make the experience more intuitive?

I made the manual language buttons much more visible by changing their shape and color. We still kept the Magic Mic of course, and even gave it a more descriptive text label. But now it was clear to users that there were other options, and it was really easy to switch between Magic Mic and manual mode with a single tap.

<!-- type: image-full-width -->
![Conversation interface design](/images/fish-in-your-ear/solution.webp)

## PIXEL BUDS

Around the same time, we were working with the Pixel Buds team on their debut launch. Conversation mode would feel even more magical when paired with an in-ear bid, so we made small tweaks to the UI to support this. One of my brilliant designers, Liu Liu, even came up with the ingenious idea of the 'ice breaker' screen. 
He had noticed in user studies that the most awkward part of the interaction was the beginning of the conversation. He made a visual screen with a standard message that the user could just show to the other person to break the ice.

<!-- type: image-full-width -->
![Slide 1](/images/fish-in-your-ear/buds.webp)
<!-- type: image-full-width -->
![Slide 2](/images/fish-in-your-ear/icebreaker.webp)

## RESULTS

The media has a fascination with real-time translations, so we received an incredible amount of press specially when the Pixel Buds feature alogn with the new UI for conversation mode was launched. More importantly, as a result of the UI changes as well as other technical improvements that made the conversation mode faster, we saw a noticeable increase in the usage of speech translations overall. While our quest for improving these and other features didn't end here, this was a great first step in making our most magical features more discoverable and easier to use.


<!-- type: image-grid -->
![Larger icons interface mockup](/images/fish-in-your-ear/chart.webp)
![Updated interface with larger icons](/images/fish-in-your-ear/quotes.webp)
